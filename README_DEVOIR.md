# üìö Guide Complet - Devoir Benchmark REST

## üéØ Vue d'Ensemble

Ce projet impl√©mente un benchmark de performance comparant 3 approches REST en Java, conforme aux exigences du devoir du Pr. LACHGAR.

**Variantes impl√©ment√©es** :
- ‚úÖ **Variant A** : JAX-RS Jersey + JPA/Hibernate
- ‚úÖ **Variant C** : Spring Boot @RestController + JPA/Hibernate  
- ‚úÖ **Variant D** : Spring Boot Spring Data REST

---

## üìã Documents Disponibles

### 1. `ANALYSE_PROJET.md`
Analyse technique compl√®te du projet :
- Architecture d√©taill√©e
- Technologies utilis√©es
- Structure de chaque variante
- Points d'attention et recommandations

### 2. `CONFORMITE_DEVOIR.md`
V√©rification de conformit√© avec les exigences du devoir :
- ‚úÖ Checklist compl√®te
- ‚ö†Ô∏è Points √† v√©rifier/compl√©ter
- Instructions pour collecter les donn√©es

### 3. `TABLEAUX_DEVOIR.md`
Templates pr√™ts √† remplir pour les tableaux T0-T7 :
- T0 : Configuration mat√©rielle/logicielle
- T1 : Sc√©narios (d√©j√† rempli)
- T2 : R√©sultats JMeter
- T3 : Ressources JVM
- T4 : D√©tails JOIN-filter
- T5 : D√©tails MIXED
- T6 : Incidents/Erreurs
- T7 : Synth√®se & Conclusion

### 4. `GUIDE_EXECUTION.md`
Guide pratique pour ex√©cuter les benchmarks :
- Commandes d'ex√©cution
- Collecte des donn√©es
- D√©pannage

---

## üöÄ D√©marrage Rapide

### √âtape 1 : Initialisation

```bash
# Rendre les scripts ex√©cutables (Linux/Mac)
chmod +x setup.sh run-benchmark.sh

# Windows PowerShell
# Les scripts .sh n√©cessitent Git Bash ou WSL

# Ex√©cuter le setup
./setup.sh
```

### √âtape 2 : Ex√©cuter les Benchmarks

```bash
# Tester toutes les variantes, tous les sc√©narios
./run-benchmark.sh a all  # Variant A
./run-benchmark.sh c all  # Variant C
./run-benchmark.sh d all  # Variant D
```

### √âtape 3 : Consulter les R√©sultats

- **Rapports JMeter** : `jmeter/results/*/index.html`
- **Grafana** : http://localhost:3000 (admin/admin)
- **Prometheus** : http://localhost:9090

### √âtape 4 : Remplir les Tableaux

Ouvrir `TABLEAUX_DEVOIR.md` et remplir avec vos r√©sultats.

---

## ‚úÖ Conformit√© aux Exigences

### Mod√®le de Donn√©es
- ‚úÖ Tables Category et Item conformes
- ‚úÖ Index cr√©√©s
- ‚úÖ Relations JPA (@ManyToOne LAZY, @OneToMany)
- ‚úÖ 2000 cat√©gories, 100 000 items

### Endpoints
- ‚úÖ Tous les endpoints demand√©s impl√©ment√©s
- ‚úÖ Pagination identique
- ‚úÖ Validation Bean Validation
- ‚úÖ Support payloads 1KB et 5KB

### Sc√©narios JMeter
- ‚úÖ 4 sc√©narios conformes (READ-heavy, JOIN-filter, MIXED, HEAVY-body)
- ‚úÖ Distribution des requ√™tes correcte
- ‚úÖ Paliers de charge conformes
- ‚úÖ CSV Data Set Config configur√©
- ‚úÖ Backend Listener InfluxDB configur√©

### Infrastructure
- ‚úÖ Docker Compose avec tous les services
- ‚úÖ Prometheus + JMX Exporter (Variant A)
- ‚úÖ Spring Actuator + Micrometer (Variants C & D)
- ‚úÖ Grafana avec dashboards
- ‚úÖ InfluxDB v2 pour m√©triques JMeter

### Optimisations
- ‚úÖ Mode optimized (JOIN FETCH) vs baseline
- ‚úÖ Variable d'environnement QUERY_MODE
- ‚úÖ Cache L2 Hibernate d√©sactiv√©

---

## üìä Workflow Recommand√© pour le Devoir

### 1. Pr√©paration (30 min)

```bash
# Setup
./setup.sh

# V√©rifier que tout fonctionne
curl http://localhost:8081/categories?page=0&size=1
curl http://localhost:8082/categories?page=0&size=1
curl http://localhost:8083/categories?page=0&size=1
```

### 2. Ex√©cution des Tests (2-3 heures)

**Pour chaque variante (A, C, D)** :

```bash
# Mode optimized (recommand√©)
export QUERY_MODE=optimized

# Ex√©cuter tous les sc√©narios
./run-benchmark.sh a all  # ~40 min par variante
./run-benchmark.sh c all
./run-benchmark.sh d all
```

**Temps estim√©** :
- READ-heavy : ~30 min (3 paliers √ó 10 min)
- JOIN-filter : ~16 min (2 paliers √ó 8 min)
- MIXED : ~20 min (2 paliers √ó 10 min)
- HEAVY-body : ~16 min (2 paliers √ó 8 min)
- **Total par variante** : ~82 min

### 3. Collecte des Donn√©es (1-2 heures)

Pour chaque run :
1. Ouvrir les rapports JMeter HTML
2. Noter les m√©triques (RPS, p50, p95, p99, Err %)
3. Exporter les m√©triques Prometheus depuis Grafana
4. Analyser les endpoints individuels
5. Remplir les tableaux T2-T6

### 4. Analyse et R√©daction (2-3 heures)

1. Comparer les r√©sultats entre variantes
2. Identifier les patterns et √©carts
3. Remplir T7 (Synth√®se & Conclusion)
4. R√©diger les recommandations d'usage

---

## üìù Livrables du Devoir

### 1. Code des Variantes ‚úÖ
- ‚úÖ Variant A (Jersey)
- ‚úÖ Variant C (Spring MVC)
- ‚úÖ Variant D (Spring Data REST)

### 2. Fichiers JMeter ‚úÖ
- ‚úÖ 4 sc√©narios (.jmx)
- ‚úÖ CSV de donn√©es de test
- ‚úÖ Payloads JSON (1KB, 5KB)

### 3. Dashboards Grafana ‚ö†Ô∏è
- ‚úÖ Dashboard JVM pr√©-configur√©
- ‚ö†Ô∏è Dashboard JMeter : √Ä cr√©er ou utiliser InfluxDB
- ‚ö†Ô∏è Exports CSV : √Ä exporter depuis Grafana
- ‚ö†Ô∏è Captures d'√©cran : √Ä faire apr√®s ex√©cution

### 4. Tableaux T0-T7 ‚ö†Ô∏è
- ‚úÖ Templates cr√©√©s dans `TABLEAUX_DEVOIR.md`
- ‚ö†Ô∏è √Ä remplir avec vos r√©sultats

### 5. Analyse et Recommandations ‚ö†Ô∏è
- ‚ö†Ô∏è √Ä r√©diger dans T7 apr√®s analyse des r√©sultats

---

## üîç Points d'Attention pour l'Analyse

### Comparaison des Variantes

**Variant A (Jersey)** :
- Avantages : L√©ger, contr√¥le total, pas d'overhead framework
- Inconv√©nients : Plus de code, gestion manuelle des transactions
- √Ä observer : Performance brute, consommation m√©moire

**Variant C (Spring MVC)** :
- Avantages : Productivit√©, gestion automatique, Spring Data JPA
- Inconv√©nients : Overhead framework, plus de d√©pendances
- √Ä observer : Impact de l'abstraction Spring

**Variant D (Spring Data REST)** :
- Avantages : D√©veloppement minimal, API HAL standardis√©e
- Inconv√©nients : Moins de contr√¥le, format HAL plus lourd
- √Ä observer : Co√ªt de l'abstraction automatique

### M√©triques Cl√©s √† Analyser

1. **D√©bit (RPS)** : Quelle variante traite le plus de requ√™tes/seconde ?
2. **Latence (p95)** : Quelle variante est la plus rapide ?
3. **Stabilit√©** : Quelle variante a le moins d'erreurs ?
4. **Ressources** : Quelle variante consomme le moins (CPU/RAM) ?
5. **Impact JOIN FETCH** : Diff√©rence entre optimized et baseline

### Observations Techniques

- **N+1 Queries** : Comparer optimized vs baseline
- **Format HAL** : Impact sur la taille des r√©ponses (Variant D)
- **Transactions** : Gestion manuelle (A) vs automatique (C, D)
- **Pagination** : Comparer l'efficacit√© entre variantes

---

## üõ†Ô∏è Commandes Utiles

### V√©rifier l'√©tat des services

```bash
# Services Docker
docker ps

# Logs d'une variante
docker logs benchmark-variant-a

# M√©triques Prometheus
curl http://localhost:9091/metrics  # Variant A
curl http://localhost:8082/actuator/prometheus  # Variant C
```

### Exporter les m√©triques

```bash
# Prometheus
curl http://localhost:9091/metrics > metrics-variant-a.txt

# Actuator
curl http://localhost:8082/actuator/prometheus > metrics-variant-c.txt
```

### Nettoyage

```bash
# Arr√™ter tous les services
docker-compose --profile variant-a down
docker-compose --profile variant-c down
docker-compose --profile variant-d down

# Arr√™ter l'infrastructure
cd docker
docker-compose down
```

---

## üìö Ressources

- **Analyse technique** : `ANALYSE_PROJET.md`
- **Conformit√©** : `CONFORMITE_DEVOIR.md`
- **Tableaux** : `TABLEAUX_DEVOIR.md`
- **Guide d'ex√©cution** : `GUIDE_EXECUTION.md`
- **Rapports JMeter** : `jmeter/results/`
- **Grafana** : http://localhost:3000
- **Prometheus** : http://localhost:9090

---

## ‚ö†Ô∏è Checklist Finale Avant Remise

- [ ] Tous les benchmarks ex√©cut√©s (A, C, D)
- [ ] Tableaux T0-T7 remplis
- [ ] Rapports JMeter HTML g√©n√©r√©s
- [ ] M√©triques Prometheus export√©es
- [ ] Dashboards Grafana configur√©s
- [ ] Captures d'√©cran des dashboards
- [ ] Analyse et synth√®se r√©dig√©es (T7)
- [ ] Recommandations d'usage formul√©es
- [ ] Code comment√© et propre
- [ ] README √† jour

---

## üéì Conseils pour la R√©daction

### Synth√®se (T7)

1. **Soyez objectif** : Basez-vous sur les donn√©es mesur√©es
2. **Justifiez les √©carts** : Expliquez pourquoi une variante est meilleure
3. **Contexte** : Mentionnez les conditions de test
4. **Recommandations** : Proposez des cas d'usage concrets

### Exemple de Justification

‚ùå **Mauvais** : "Variant A est meilleur"
‚úÖ **Bon** : "Variant A offre 15% de RPS en plus que Variant C car il n'a pas l'overhead du framework Spring, mais n√©cessite 30% plus de code"

### Recommandations d'Usage

- **Lecture relationnelle** : Bas√© sur les r√©sultats JOIN-filter
- **Forte √©criture** : Bas√© sur les r√©sultats MIXED
- **Exposition rapide** : Bas√© sur la facilit√© de d√©veloppement

---

**Bon courage pour votre devoir ! üöÄ**

*N'h√©sitez pas √† consulter les autres documents pour plus de d√©tails.*

